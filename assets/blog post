<p>I've been a fan of <a href="http://www.overheardinnewyork.com/">Overheard in New York</a> for <a href="http://persistent.info/archives/2005/04/29/overheard-nyc">a while</a>. At some point, it occurred to me that each quote has a pretty precise location attached to it and that it would be cool to plot all of them on a map. I eventually got motivated enough to actually do it. The result is <a href="http://persistent.info/overplot/">overplot</a>, a <a href="http://www.google.com/apis/maps/">Google Maps API</a>-powered visualization of all of the quotes I could get my hands on.</p>

<h3>Technical Details</h3>

<p>The most basic issue with implementing this is geocoding all of the location strings (like "Canal & Broadway") to a latitude/longitude pair. When I began this, the best option seemed to be <a href="http://geocoder.us">geocoder.us</a>. While it was good enough for prototyping, it quickly became apparent that the quality of data was not good enough. The most severe problem seemed to be that addresses in the southern part of Manhattan were off by half a block to the northwest. Thankfully, a few weeks after I began working on this, Google added a <a href="http://www.google.com/apis/maps/documentation/#Geocoding_Etc">geocoding</a> component to their API. Their geocoder turned out to be much faster and reliable. It is not perfect, but since the set of addresses is pretty tightly constrained, I was able to add some rewriting rules to make the input more easily parsed. As of right now, 54% of the addresses are geocoded. One remaining issue is that some the locations are actually business (like "Saks Fifth Avenue"). I may be able to use the <a href="http://code.google.com/apis/ajaxsearch/">Google AJAX Search API</a> to do local searches for them and get their actual addresses.</p>

<p>I didn't want to directly scrape the HTML of the site to extract all of the quotes. I ended up using the data stored in <a href="<a href="http://www.google.com/reader/public/atom/feed/http%3A%2F%2Fwww.overheardinny.com%2Findex.xml">Google Reader's archive of the site's feed</a>. This allowed me to get at the quotes themselves more easily, without having to worry about the chrome of the site. Going back to October 6, 2005, I had in hand 5,578 quotes at 2838 locations.</p>

<p>Since I had accumulated so many quotes, indicating them with the standard marker object had performance problems since so many can be visible in the same area. This is a well-known problem with the version 2 of the Maps API, and the traditional solution is <a href="http://groups.google.com/group/Google-Maps-API/search?q=clustering">clustering</a>. However, that doesn't really make sense because when zoomed in at the street level, one has no choice but to display the hundred or so markers that are visible at the same time (the norther part of Manhattan is particularly densely covered).</p>

<p>In the end, my solution was to do my own marker implementation. Instead of each marker being its own overlay, I put all of them in the same overlay (see the <code>QuotesOverlay</code> class). Additionally, I did not split each marker into several layers (shadow, image, click area) - having the shadow be part of the image works well enough. In order to deal with clicks while in the shadow of an info window, I added a global click handler that checks if the click event falls in the boundaries of a marker (see the <code>handleMapClick</code>). Finally, I hide and show markers so that only those bounded by the currently viewed area are displayed. All of this led to a performance improvement by a factor of 8 on Firefox Mac.</p>

<p>I then ran into a user interface problem. Even with marker rendering being efficient, when zoomed out the island of Manhattan becomes a sea of red, which is not very useful. I decided that switching to a neighborhood mode made more sense there. The problem was where to get the neighborhood boundaries. The <a href="http://www.nyc.gov/html/tlc/downloads/pdf/passenger_info_map.pdf">map</a> used in cabs seemed like a good start, but it made some interesting choices (e.g. TriBeCa was not bounded by Canal St.). New York Magazine's <a href=
"http://www.newyorkmetro.com/realestate/articles/03/realestate2003/neighborhood_map.htm">map</a> also turned out to be of dubious quality (e.g. it combined Gramercy and Murray Hill). In the end, the best resource turned out to be <a href="http://en.wikipedia.org/wiki/List_of_Manhattan_neighborhoods">the Wikipedia's list</a>. Even there there is some debate (an mild <a href="http://en.wikipedia.org/w/index.php?title=Spanish_Harlem&action=history">edit war</a> on the souther border of Spanish Harlem - 86th or 96th street - appears to be going on). I'm not entirely satisfied with the current divisions, but they generally make sense.</p>

<p>Once I actually plotted the 28 neighborhoods on the map, I noticed that it was slow to redraw, especially in Firefox. I was using <a href="http://www.google.com/apis/maps/documentation/reference.html#GPolyline"><code>GPolyline</code>s</a> to draw the neighborhood outlines, one per area. Possily due to the switch to SVG for polyline rendering, this seemed to have high overheard. In the end, similarly to my solution to the marker performance problem, I switched to a single overlay for all neighborhood outlines. Inside this overlay I used a <a href="http://whatwg.org/specs/web-apps/current-work/#scs-dynamic">canvas</a> object to do my own rendering. To deal with MSIE's lack of a canvas implementation, I used the <a href="http://sourceforge.net/projects/excanvas/">ExplorerCanvas</a> implementation of the interface on top of MSIE's VML API.</p>

<p>The site loads all of the data upfront (in a 728K almost-but-not-quite JSON file). This allowed me to do a simple client-side search that works pretty quickly once all of the quotes are tokenized (done the first time a search is executed).</p>